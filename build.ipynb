{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Docker Images and Register with ECR\n",
    "This notebook is an extension of the build [CPU](https://github.com/daniel-fudge/sagemaker-tennis/blob/master/build-cpu.ipynb) and [GPU](https://github.com/daniel-fudge/sagemaker-tennis/blob/master/build-gpu.ipynb) notebooks in the related [Tennis](https://github.com/daniel-fudge/sagemaker-tennis) repo. If you are unfamiliar with building Docker images and registering them in AWS [ECR](https://aws.amazon.com/ecr/), please see the [Tennis](https://github.com/daniel-fudge/sagemaker-tennis) repo.\n",
    "\n",
    "If working on your own fork, you may want to set the following.\n",
    "```shell\n",
    "git config --global user.name \"Your Name\"\n",
    "git config --global user.email your.email@domain.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECR Access\n",
    "When you first created an SakeMaker instance either you made or selected a custom role or the system created one for you.  I believe there has been a change in the service since I initially made my `AmazonSageMaker-ExecutionRole`.  To execute the push below I had to add the `AmazonEC2ContainerRegistryFullAccess` policy to my SageMaker [IAM](https://console.aws.amazon.com/iam) role.  Specifically the `ecr:InitiateLayerUpload` access had to be added for images other than the SageMaker images covered in the SageMaker full access policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and register the CPU container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod -R 755 container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting CPU image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  3.113MB\n",
      "Step 1/10 : ARG REGION=us-east-1\n",
      "Step 2/10 : FROM 520713654638.dkr.ecr.$REGION.amazonaws.com/sagemaker-pytorch:1.1.0-cpu-py3\n",
      " ---> d374fb352c72\n",
      "Step 3/10 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> b4524ab0cb43\n",
      "Step 4/10 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> d914220df64a\n",
      "Step 5/10 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 3964e488f753\n",
      "Step 6/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 2ba02b18656e\n",
      "Step 7/10 : COPY /src /opt/ml/code\n",
      " ---> f098ab19b6e5\n",
      "Step 8/10 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Running in e4887c56c254\n",
      "Removing intermediate container e4887c56c254\n",
      " ---> 88c7d553d274\n",
      "Step 9/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 2c45897e93d5\n",
      "Removing intermediate container 2c45897e93d5\n",
      " ---> 6e62ed907a84\n",
      "Step 10/10 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 1f796dd29fc4\n",
      "Removing intermediate container 1f796dd29fc4\n",
      " ---> b862e3b9477f\n",
      "Successfully built b862e3b9477f\n",
      "Successfully tagged portfolio-optimization-cpu:latest\n",
      "Building CPU image\n",
      "The push refers to repository [031118886020.dkr.ecr.us-east-1.amazonaws.com/portfolio-optimization-cpu]\n",
      "\n",
      "\u001b[1B9d918614: Preparing \n",
      "\u001b[1Bbf3f4f2c: Preparing \n",
      "\u001b[1B31a845ec: Preparing \n",
      "\u001b[1B33237a0d: Preparing \n",
      "\u001b[1B532f8c4c: Preparing \n",
      "\u001b[1Becc4e4d4: Preparing \n",
      "\u001b[1B808cebd3: Preparing \n",
      "\u001b[1Bf05eda79: Preparing \n",
      "\u001b[1B71db9add: Preparing \n",
      "\u001b[1B53464ab3: Preparing \n",
      "\u001b[1Bc4bd5031: Preparing \n",
      "\u001b[1Bd01ff144: Preparing \n",
      "\u001b[1B7f77d9db: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[17Bd918614: Pushed lready exists 9MB6A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[16A\u001b[2Klatest: digest: sha256:d3d214b87814d7dfb39cf50f9176ea5fe2b07d0db36c17d550719310cdef0de9 size: 3881\n"
     ]
    }
   ],
   "source": [
    "!./container/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and register the GPU container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting GPU image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  3.113MB\n",
      "Step 1/10 : ARG REGION=us-east-1\n",
      "Step 2/10 : FROM 520713654638.dkr.ecr.$REGION.amazonaws.com/sagemaker-pytorch:1.1.0-gpu-py3\n",
      " ---> adbf113505a2\n",
      "Step 3/10 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 635764385479\n",
      "Step 4/10 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> 9449a77875e9\n",
      "Step 5/10 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 783e15fb6bc1\n",
      "Step 6/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 537b2b3c690c\n",
      "Step 7/10 : COPY /src /opt/ml/code\n",
      " ---> 5e6d4f64df69\n",
      "Step 8/10 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Running in 0b83e4a15ed7\n",
      "Removing intermediate container 0b83e4a15ed7\n",
      " ---> 4005e4c5db03\n",
      "Step 9/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 220f6367bd88\n",
      "Removing intermediate container 220f6367bd88\n",
      " ---> b41aa1fb2306\n",
      "Step 10/10 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 466007f40d4a\n",
      "Removing intermediate container 466007f40d4a\n",
      " ---> d370088e925f\n",
      "Successfully built d370088e925f\n",
      "Successfully tagged portfolio-optimization-gpu:latest\n",
      "Building GPU image\n",
      "The push refers to repository [031118886020.dkr.ecr.us-east-1.amazonaws.com/portfolio-optimization-gpu]\n",
      "\n",
      "\u001b[1Bb1ebc5e9: Preparing \n",
      "\u001b[1B51ea8b0b: Preparing \n",
      "\u001b[1B3657abf8: Preparing \n",
      "\u001b[1B33237a0d: Preparing \n",
      "\u001b[1B34a0d5c7: Preparing \n",
      "\u001b[1Bf3470ef5: Preparing \n",
      "\u001b[1B808cebd3: Preparing \n",
      "\u001b[1Ba36844e2: Preparing \n",
      "\u001b[1Bac83281f: Preparing \n",
      "\u001b[1B53464ab3: Preparing \n",
      "\u001b[1B7a178c2c: Preparing \n",
      "\u001b[1B1f16c1bd: Preparing \n",
      "\u001b[1Ba3d32a13: Preparing \n",
      "\u001b[1Bc432fc3d: Preparing \n",
      "\u001b[1Bd718ffb0: Preparing \n",
      "\u001b[1Bf211099a: Preparing \n",
      "\u001b[1Bb5b15f16: Preparing \n",
      "\u001b[1B0239569d: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[22B1ebc5e9: Pushed lready exists 9MB1A\u001b[2K\u001b[16A\u001b[2K\u001b[21A\u001b[2K\u001b[14A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[21A\u001b[2K\u001b[22A\u001b[2Klatest: digest: sha256:cb31ddf3c1c84d6ce9dda363faa3485eeacdfb7e62f91e6fa57df8e3c24a2a61 size: 4937\n"
     ]
    }
   ],
   "source": [
    "!./container/build_and_push.sh gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Notebook for local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has root access.\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the CPU model locally\n",
    "Since we only want to check the functionality, we will start at day 2900.  There are only 2922 days worth of signals so we are only letting the model trade for 22 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpy256mg5d_algo-1-rtqam_1 ... \n",
      "\u001b[1BAttaching to tmpy256mg5d_algo-1-rtqam_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,779 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,783 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,797 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,798 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,799 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,800 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,800 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:28,800 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m /usr/bin/python -m pip install . \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=1288587 sha256=4e78975f5e2c81de5bfb24b5d4bd1e93ba5e32ae35adcb782a4127b6e68f2ee7\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-s9xjlnuf/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Successfully built train\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:30,586 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m 2020-07-13 00:45:30,600 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"current_host\": \"algo-1-rtqam\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m         \"algo-1-rtqam\"\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m         \"start_day\": 2900\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"job_name\": \"portfolio-optimization-cpu-2020-07-13-00-45-26-426\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"master_hostname\": \"algo-1-rtqam\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m         \"current_host\": \"algo-1-rtqam\",\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m             \"algo-1-rtqam\"\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_HOSTS=[\"algo-1-rtqam\"]\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_HPS={\"start_day\":2900}\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-rtqam\",\"hosts\":[\"algo-1-rtqam\"]}\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_CURRENT_HOST=algo-1-rtqam\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-rtqam\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-rtqam\"],\"hyperparameters\":{\"start_day\":2900},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"portfolio-optimization-cpu-2020-07-13-00-45-26-426\",\"log_level\":20,\"master_hostname\":\"algo-1-rtqam\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-rtqam\",\"hosts\":[\"algo-1-rtqam\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_USER_ARGS=[\"--start_day\",\"2900\"]\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m SM_HP_START_DAY=2900\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m /usr/bin/python -m train --start_day 2900\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m \n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m CPU activated.\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Setting up the environment.\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Size of action space: 10\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m State space per agent: 71\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Training the agent.\n",
      "\u001b[36malgo-1-rtqam_1  |\u001b[0m Beginning initial training.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "start_day = 2900\n",
    "role = get_execution_role()\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local',\n",
    "                      image_name='portfolio-optimization-cpu:latest',\n",
    "                      hyperparameters={'start_day': start_day})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate the ECR image just built and pushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/portfolio-optimization-cpu:latest'.format(account, region)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.m5.large',\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters={'start_day': start_day})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "job_name = estimator._current_job_name\n",
    "print(bucket)\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy and unpack the result archive\n",
    "Since we didn't start trading until nearly the end, the results are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "key = '{}/output/output.tar.gz'.format(estimator._current_job_name)\n",
    "print(key)\n",
    "s3.Bucket(bucket).download_file(key, 'output.tar.gz')\n",
    "shutil.unpack_archive('output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='history.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Tennis Repo](https://github.com/daniel-fudge/sagemaker-tennis)\n",
    "- [Amazon ECS](https://aws.amazon.com/ecs/)\n",
    "\n",
    "#### SageMaker\n",
    "- [SageMaker Example:  Extending PyTorch Container](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/pytorch_extending_our_containers)\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)\n",
    "- [SageMaker PyTorch container](https://github.com/aws/sagemaker-pytorch-container)\n",
    "- [SageMaker Instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/)\n",
    "- [SageMaker Instance prices](https://aws.amazon.com/sagemaker/pricing/)\n",
    "\n",
    "#### Docker\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [Docker home page](http://www.docker.com)\n",
    "- [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "- [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "- [docker run reference](https://docs.docker.com/engine/reference/run/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
